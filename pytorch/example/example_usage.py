"""
QuantGRU é‡åŒ–åº“ä½¿ç”¨ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ QuantGRU è¿›è¡Œï¼š
- åŸºæœ¬æ¨ç†ï¼ˆæµ®ç‚¹/é‡åŒ–ï¼‰
- é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰
- æ ¡å‡†æ–¹æ³•é€‰æ‹©ï¼ˆMinMax / Histogramï¼‰
- åŒå‘ GRU
- ONNX å¯¼å‡ºï¼ˆQDQ / å®šç‚¹ / æµ®ç‚¹æ¨¡å¼ï¼‰
"""

import torch
import torch.nn as nn

# æ·»åŠ åº“è·¯å¾„ï¼ˆæ ¹æ®å®é™…å®‰è£…ä½ç½®ä¿®æ”¹ï¼‰
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from quant_gru import QuantGRU


def example_basic_usage():
    """
    ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨ï¼ˆéé‡åŒ–ï¼‰
    
    ä¸ nn.GRU ç”¨æ³•å®Œå…¨ä¸€è‡´
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨ï¼ˆéé‡åŒ–ï¼‰")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºæ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True  # è¾“å…¥æ ¼å¼ [batch, seq, feature]
    ).cuda()
    
    # åˆ›å»ºè¾“å…¥æ•°æ®
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    
    # å‰å‘ä¼ æ’­
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}")
    print("âœ… åŸºæœ¬ä½¿ç”¨å®Œæˆï¼")


def example_quantization_with_json():
    """
    ç¤ºä¾‹ 2: ä½¿ç”¨ JSON é…ç½®è¿›è¡Œé‡åŒ–
    
    æ¨èæ–¹å¼ï¼šé€šè¿‡ JSON æ–‡ä»¶é…ç½®é‡åŒ–å‚æ•°
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2: ä½¿ç”¨ JSON é…ç½®è¿›è¡Œé‡åŒ–")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # 1. åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½é…ç½®
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # åŠ è½½ JSON é…ç½®ï¼ˆè‡ªåŠ¨è®¾ç½® use_quantizationï¼‰
    config_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "config/gru_quant_bitwidth_config.json"
    )
    gru.load_bitwidth_config(config_path)
    print(f"âœ… åŠ è½½é…ç½®: {config_path}")
    print(f"   é‡åŒ–å¼€å…³: use_quantization = {gru.use_quantization}")
    
    # 2. æ ¡å‡†ï¼ˆä½¿ç”¨ä»£è¡¨æ€§æ•°æ®ï¼‰
    print("\nğŸ“Š å¼€å§‹æ ¡å‡†...")
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru.calibrate(calibration_data)
    print("âœ… æ ¡å‡†å®Œæˆï¼")
    
    # 3. æ¨ç†
    print("\nğŸš€ å¼€å§‹æ¨ç†...")
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}")
    print("âœ… é‡åŒ–æ¨ç†å®Œæˆï¼")


def example_quantization_manual(bitwidth=8):
    """
    ç¤ºä¾‹ 3: æ‰‹åŠ¨é…ç½®é‡åŒ–å‚æ•°
    
    ä¸ä½¿ç”¨ JSON æ–‡ä»¶ï¼Œç›´æ¥åœ¨ä»£ç ä¸­è®¾ç½®
    
    Args:
        bitwidth: é‡åŒ–ä½å®½ï¼ˆ8 æˆ– 16ï¼‰
    """
    print("\n" + "=" * 60)
    print(f"ç¤ºä¾‹ 3: æ‰‹åŠ¨é…ç½®é‡åŒ–å‚æ•° ({bitwidth}bit)")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # 1. åˆ›å»ºæ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # 2. è®¾ç½®ä½å®½
    gru.set_all_bitwidth(bitwidth)
    print(f"âœ… è®¾ç½®ä½å®½: {bitwidth}bit å¯¹ç§°é‡åŒ–")
    
    # 3. æ ¡å‡†
    print("\nğŸ“Š å¼€å§‹æ ¡å‡†...")
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru.calibrate(calibration_data)
    print("âœ… æ ¡å‡†å®Œæˆï¼")
    
    # 4. å¼€å¯é‡åŒ–å¹¶æ¨ç†
    gru.use_quantization = True
    print(f"   é‡åŒ–å¼€å…³: use_quantization = {gru.use_quantization}")
    
    print("\nğŸš€ å¼€å§‹æ¨ç†...")
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}")
    print(f"âœ… {bitwidth}bit é‡åŒ–æ¨ç†å®Œæˆï¼")


def example_compare_precision(bitwidth=8):
    """
    ç¤ºä¾‹ 4: æ¯”è¾ƒé‡åŒ–å‰åçš„ç²¾åº¦å·®å¼‚
    
    Args:
        bitwidth: é‡åŒ–ä½å®½ï¼ˆ8 æˆ– 16ï¼‰
    """
    print("\n" + "=" * 60)
    print(f"ç¤ºä¾‹ 4: æ¯”è¾ƒé‡åŒ–å‰åçš„ç²¾åº¦å·®å¼‚ ({bitwidth}bit)")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºéé‡åŒ–æ¨¡å‹ï¼ˆåŸºå‡†ï¼‰
    gru_float = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True,
        use_quantization=False
    ).cuda()
    
    # åˆ›å»ºé‡åŒ–æ¨¡å‹ï¼ˆå¤åˆ¶æƒé‡ï¼‰
    gru_quant = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # å¤åˆ¶æƒé‡
    gru_quant.weight_ih_l0.data.copy_(gru_float.weight_ih_l0.data)
    gru_quant.weight_hh_l0.data.copy_(gru_float.weight_hh_l0.data)
    gru_quant.bias_ih_l0.data.copy_(gru_float.bias_ih_l0.data)
    gru_quant.bias_hh_l0.data.copy_(gru_float.bias_hh_l0.data)
    
    # æ ¡å‡†å¹¶å¼€å¯é‡åŒ–
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    gru_quant.set_all_bitwidth(bitwidth)
    gru_quant.calibrate(x)
    gru_quant.use_quantization = True
    
    # æ¯”è¾ƒè¾“å‡º
    gru_float.eval()
    gru_quant.eval()
    
    with torch.no_grad():
        output_float, _ = gru_float(x)
        output_quant, _ = gru_quant(x)
    
    # è®¡ç®—è¯¯å·®
    mse = torch.mean((output_float - output_quant) ** 2).item()
    cos_sim = torch.nn.functional.cosine_similarity(
        output_float.flatten().unsqueeze(0),
        output_quant.flatten().unsqueeze(0)
    ).item()
    
    print(f"ğŸ“Š {bitwidth}bit ç²¾åº¦æ¯”è¾ƒç»“æœ:")
    print(f"   MSE (å‡æ–¹è¯¯å·®):     {mse:.6f}")
    print(f"   ä½™å¼¦ç›¸ä¼¼åº¦:         {cos_sim:.6f}")
    print(f"âœ… {bitwidth}bit ç²¾åº¦æ¯”è¾ƒå®Œæˆï¼")


def example_training(bitwidth=8):
    """
    ç¤ºä¾‹ 5: é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰
    
    ä»»åŠ¡ï¼šå­¦ä¹ è¾“å…¥åºåˆ—çš„ç®€å•å˜æ¢ï¼ˆè¾“å…¥ä¹˜ä»¥å›ºå®šç³»æ•°ï¼‰
    æ³¨æ„ï¼šå‰å‘ä¼ æ’­ä½¿ç”¨é‡åŒ–ï¼Œåå‘ä¼ æ’­ä½¿ç”¨æµ®ç‚¹
    
    Args:
        bitwidth: é‡åŒ–ä½å®½ï¼ˆ8 æˆ– 16ï¼‰
    """
    print("\n" + "=" * 60)
    print(f"ç¤ºä¾‹ 5: é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ ({bitwidth}bit)")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 64  # ä¸ input_size ç›¸åŒï¼Œä¾¿äºæ„é€ ç›®æ ‡
    batch_size = 8
    seq_len = 20
    num_epochs = 5
    
    # åˆ›å»ºæ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œç»“æœä¸€è‡´
    torch.manual_seed(42)
    
    # ç”Ÿæˆå›ºå®šçš„è®­ç»ƒæ•°æ®ï¼ˆå­¦ä¹ è¾“å…¥çš„ 0.5 å€å˜æ¢ï¼‰
    x_train = torch.randn(batch_size, seq_len, input_size).cuda() * 0.5
    target_train = x_train * 0.5  # ç®€å•çš„çº¿æ€§å˜æ¢ä½œä¸ºç›®æ ‡
    
    # æ ¡å‡†
    gru.set_all_bitwidth(bitwidth)
    gru.calibrate(x_train)
    gru.use_quantization = True
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)
    
    # è®­ç»ƒå¾ªç¯
    gru.train()
    print(f"\nğŸ‹ï¸ å¼€å§‹ {bitwidth}bit é‡åŒ–è®­ç»ƒ...")
    
    for epoch in range(num_epochs):
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        output, _ = gru(x_train)
        
        # è®¡ç®—æŸå¤±
        loss = torch.mean((output - target_train) ** 2)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        print(f"   Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.6f}")
    
    print(f"âœ… {bitwidth}bit è®­ç»ƒå®Œæˆï¼ï¼ˆLoss åº”æŒç»­ä¸‹é™ï¼‰")


def example_calibration_method():
    """
    ç¤ºä¾‹ 6: æ ¡å‡†æ–¹æ³•é€‰æ‹©
    
    QuantGRU æ”¯æŒä¸¤ç§æ ¡å‡†æ–¹æ³•:
    - 'minmax': å¿«é€Ÿï¼Œé€‚åˆå¯¹é€Ÿåº¦è¦æ±‚é«˜çš„åœºæ™¯
    - 'histogram': AIMET é£æ ¼ï¼Œç²¾åº¦æ›´é«˜ï¼Œé€‚åˆå¯¹ç²¾åº¦è¦æ±‚é«˜çš„åœºæ™¯
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 6: æ ¡å‡†æ–¹æ³•é€‰æ‹©")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºåŸºå‡†æ¨¡å‹ï¼ˆFP32ï¼‰
    gru_base = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True,
        use_quantization=False
    ).cuda()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    torch.manual_seed(42)
    test_input = torch.randn(batch_size, seq_len, input_size).cuda()
    
    # FP32 åŸºå‡†è¾“å‡º
    gru_base.eval()
    with torch.no_grad():
        fp32_output, _ = gru_base(test_input)
    
    print("\nğŸ“Š å¯¹æ¯”ä¸¤ç§æ ¡å‡†æ–¹æ³•:")
    print("-" * 50)
    
    results = {}
    
    for method in ['minmax', 'histogram']:
        # åˆ›å»ºé‡åŒ–æ¨¡å‹ï¼ˆå¤åˆ¶æƒé‡ï¼‰
        gru_quant = QuantGRU(
            input_size=input_size,
            hidden_size=hidden_size,
            batch_first=True
        ).cuda()
        
        # å¤åˆ¶æƒé‡
        gru_quant.weight_ih_l0.data.copy_(gru_base.weight_ih_l0.data)
        gru_quant.weight_hh_l0.data.copy_(gru_base.weight_hh_l0.data)
        gru_quant.bias_ih_l0.data.copy_(gru_base.bias_ih_l0.data)
        gru_quant.bias_hh_l0.data.copy_(gru_base.bias_hh_l0.data)
        
        # è®¾ç½®æ ¡å‡†æ–¹æ³•
        gru_quant.calibration_method = method
        
        # è®¾ç½®ä½å®½å¹¶æ ¡å‡†
        gru_quant.set_all_bitwidth(16)
        
        # å¤šæ‰¹æ¬¡æ ¡å‡†ï¼ˆhistogram æ–¹æ³•åœ¨å¤šæ‰¹æ¬¡ä¸‹æ•ˆæœæ›´å¥½ï¼‰
        for _ in range(3):
            calib_data = torch.randn(batch_size, seq_len, input_size).cuda()
            gru_quant.calibrate(calib_data)
        
        # å¼€å¯é‡åŒ–å¹¶æ¨ç†
        gru_quant.use_quantization = True
        gru_quant.eval()
        
        with torch.no_grad():
            quant_output, _ = gru_quant(test_input)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        cos_sim = torch.nn.functional.cosine_similarity(
            fp32_output.flatten().unsqueeze(0),
            quant_output.flatten().unsqueeze(0)
        ).item()
        
        results[method] = cos_sim
        method_desc = "MinMax (å¿«é€Ÿ)" if method == 'minmax' else "Histogram (é«˜ç²¾åº¦)"
        print(f"   {method_desc:<20} ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.6f}")
    
    print("-" * 50)
    print("\nğŸ’¡ é€‰æ‹©å»ºè®®:")
    print("   â€¢ minmax:    æ ¡å‡†é€Ÿåº¦å¿«ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£å’Œè°ƒè¯•")
    print("   â€¢ histogram: ç²¾åº¦æ›´é«˜ï¼Œé€‚åˆæœ€ç»ˆéƒ¨ç½²ï¼ˆæ¨èï¼‰")
    print(f"\n   é»˜è®¤ä½¿ç”¨ 'histogram' æ–¹æ³•")
    print("âœ… æ ¡å‡†æ–¹æ³•å¯¹æ¯”å®Œæˆï¼")

def example_bidirectional():
    """
    ç¤ºä¾‹ 7: åŒå‘ GRU
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 7: åŒå‘ GRU")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºåŒå‘æ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True,
        bidirectional=True  # åŒå‘
    ).cuda()
    
    # æ ¡å‡†å¹¶å¼€å¯é‡åŒ–
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    gru.set_all_bitwidth(8)
    gru.calibrate(x)
    gru.use_quantization = True
    
    # æ¨ç†
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}  (hidden_size * 2 = {hidden_size * 2})")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}  (num_directions = 2)")
    print("âœ… åŒå‘ GRU å®Œæˆï¼")


def example_onnx_export():
    """
    ç¤ºä¾‹ 8: ONNX å¯¼å‡º
    
    QuantGRU æ”¯æŒå¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œä¾¿äºéƒ¨ç½²åˆ°å„ç±»æ¨ç†å¼•æ“ã€‚
    
    å¯¼å‡ºæ¨¡å¼è¯´æ˜:
    - export_mode=False (é»˜è®¤): ä½¿ç”¨ CUDA C++ å®ç°ï¼ˆé«˜æ€§èƒ½æ¨ç†ï¼‰
    - export_mode=True: ä½¿ç”¨çº¯ PyTorch å®ç°ï¼ˆå¯è¢« ONNX è¿½è¸ªï¼‰
    
    å¯¼å‡ºæ ¼å¼ (export_format):
    - 'float': æµ®ç‚¹æ ¼å¼ï¼ˆé»˜è®¤ï¼Œä¸ Haste GRU è¡Œä¸ºä¸€è‡´ï¼‰
    - 'qdq': QDQ æ ¼å¼ï¼Œé‡åŒ–æ¨¡å‹æ¨èï¼ˆéœ€è¦å…ˆæ ¡å‡†ï¼‰
    - 'fixedpoint': çº¯å®šç‚¹ï¼Œä¸ CUDA é‡åŒ–å®Œå…¨ä¸€è‡´ï¼ˆç²¾åº¦éªŒè¯ï¼‰
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 8: ONNX å¯¼å‡º")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 1
    seq_len = 20
    
    # 1. åˆ›å»ºå¹¶é…ç½®æ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    print("\nğŸ“¦ æ­¥éª¤ 1: é…ç½®é‡åŒ–å‚æ•°")
    gru.set_all_bitwidth(16)  # 16bit é‡åŒ–
    print("   âœ… è®¾ç½® 16bit é‡åŒ–")
    
    # 2. æ ¡å‡†
    print("\nğŸ“Š æ­¥éª¤ 2: æ ¡å‡†æ¨¡å‹")
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru.calibrate(calibration_data)
    gru.finalize_calibration()
    gru.use_quantization = True
    print("   âœ… æ ¡å‡†å®Œæˆ")
    
    # 3. åˆ‡æ¢åˆ°å¯¼å‡ºæ¨¡å¼
    print("\nğŸ”„ æ­¥éª¤ 3: åˆ‡æ¢åˆ°å¯¼å‡ºæ¨¡å¼")
    gru.export_mode = True
    gru.eval()
    print(f"   export_mode = {gru.export_mode}")
    print(f"   å¯¼å‡ºæ ¼å¼: {gru.export_format}")
    
    # 4. å¯¼å‡º ONNX
    print("\nğŸ“¤ æ­¥éª¤ 4: å¯¼å‡º ONNX æ¨¡å‹")
    dummy_input = torch.randn(batch_size, seq_len, input_size).cuda()
    onnx_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "quant_gru_example.onnx"
    )
    
    torch.onnx.export(
        gru,
        dummy_input,
        onnx_path,
        input_names=['input'],
        output_names=['output', 'hidden'],
        dynamic_axes={
            'input': {0: 'batch', 1: 'seq_len'},
            'output': {0: 'batch', 1: 'seq_len'}
        },
        opset_version=14,
        dynamo=False,  # ä½¿ç”¨ä¼ ç»Ÿ TorchScript å¯¼å‡ºï¼Œé¿å… torch.export å…¼å®¹æ€§é—®é¢˜
        verbose=False
    )
    print(f"   âœ… å¯¼å‡ºæˆåŠŸ: {onnx_path}")
    
    # 5. éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
    print("\nğŸ” æ­¥éª¤ 5: éªŒè¯ ONNX æ¨¡å‹")
    try:
        import onnx
        model = onnx.load(onnx_path)
        onnx.checker.check_model(model)
        print("   âœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print(f"\n   æ¨¡å‹ä¿¡æ¯:")
        print(f"   - IR ç‰ˆæœ¬: {model.ir_version}")
        print(f"   - Opset ç‰ˆæœ¬: {model.opset_import[0].version}")
        print(f"   - è¾“å…¥æ•°é‡: {len(model.graph.input)}")
        print(f"   - è¾“å‡ºæ•°é‡: {len(model.graph.output)}")
    except ImportError:
        print("   âš ï¸ æœªå®‰è£… onnx åº“ï¼Œè·³è¿‡éªŒè¯")
    except Exception as e:
        print(f"   âš ï¸ éªŒè¯å¤±è´¥: {e}")
    
    # 6. æ¢å¤ CUDA æ¨¡å¼
    gru.export_mode = False
    print(f"\nğŸ”„ æ¢å¤ CUDA æ¨¡å¼: export_mode = {gru.export_mode}")
    
    print("\nâœ… ONNX å¯¼å‡ºç¤ºä¾‹å®Œæˆï¼")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(onnx_path):
        os.remove(onnx_path)
        print(f"   å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {onnx_path}")


def example_onnx_export_modes():
    """
    ç¤ºä¾‹ 9: ONNX å¯¼å‡ºæ ¼å¼å¯¹æ¯”
    
    æ¼”ç¤ºä¸‰ç§ ONNX å¯¼å‡ºæ ¼å¼çš„åŒºåˆ«å’Œä½¿ç”¨åœºæ™¯
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 9: ONNX å¯¼å‡ºæ ¼å¼å¯¹æ¯”")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 4
    seq_len = 20
    
    # åˆ›å»ºåŸºå‡†æ¨¡å‹
    gru_base = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # æ ¡å‡†
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru_base.set_all_bitwidth(16)
    gru_base.calibrate(calibration_data)
    gru_base.finalize_calibration()
    gru_base.use_quantization = True
    
    # è·å– CUDA å‚è€ƒè¾“å‡º
    gru_base.eval()
    test_input = torch.randn(batch_size, seq_len, input_size).cuda()
    with torch.no_grad():
        cuda_output, _ = gru_base(test_input)
    
    print("\nğŸ“Š å¯¹æ¯”ä¸‰ç§ ONNX å¯¼å‡ºæ ¼å¼:")
    print("-" * 50)
    
    modes = [
        ('qdq', 'QDQ æ ¼å¼ï¼ˆé‡åŒ–æ¨èï¼‰'),
        ('fixedpoint', 'çº¯å®šç‚¹æ ¼å¼'),
        ('float', 'æµ®ç‚¹æ ¼å¼ï¼ˆé»˜è®¤ï¼‰')
    ]
    
    gru_base.export_mode = True
    
    for mode, desc in modes:
        gru_base.export_format = mode
        
        with torch.no_grad():
            export_output, _ = gru_base(test_input)
        
        # è®¡ç®—ä¸ CUDA è¾“å‡ºçš„ç›¸ä¼¼åº¦
        cos_sim = torch.nn.functional.cosine_similarity(
            cuda_output.flatten().unsqueeze(0),
            export_output.flatten().unsqueeze(0)
        ).item()
        
        mse = torch.mean((cuda_output - export_output) ** 2).item()
        
        print(f"\n   æ¨¡å¼: {mode}")
        print(f"   æè¿°: {desc}")
        print(f"   ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.6f}")
        print(f"   MSE: {mse:.8f}")
    
    gru_base.export_mode = False
    
    print("\n" + "-" * 50)
    print("\nğŸ’¡ æ¨¡å¼é€‰æ‹©å»ºè®®:")
    print("   â€¢ 'qdq':        ç”Ÿäº§éƒ¨ç½²ï¼Œæ¨ç†å¼•æ“è‡ªåŠ¨ä¼˜åŒ–")
    print("   â€¢ 'fixedpoint': ç²¾åº¦éªŒè¯ï¼Œä¸ CUDA å®Œå…¨ä¸€è‡´")
    print("   â€¢ 'float':      è°ƒè¯•å’ŒåŸºå‡†æµ‹è¯•")
    
    print("\nâœ… å¯¼å‡ºæ¨¡å¼å¯¹æ¯”å®Œæˆï¼")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("=" * 60)
    print("  QuantGRU é‡åŒ–åº“ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯: éœ€è¦ CUDA æ”¯æŒ")
        return
    
    try:
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        example_basic_usage()
        example_quantization_with_json()
        
        # ç¤ºä¾‹ 3: æ‰‹åŠ¨é…ç½®é‡åŒ–å‚æ•°ï¼ˆ8bit å’Œ 16bitï¼‰
        example_quantization_manual(bitwidth=8)
        example_quantization_manual(bitwidth=16)
        
        # ç¤ºä¾‹ 4: æ¯”è¾ƒé‡åŒ–å‰åçš„ç²¾åº¦å·®å¼‚ï¼ˆ8bit å’Œ 16bitï¼‰
        example_compare_precision(bitwidth=8)
        example_compare_precision(bitwidth=16)
        
        # ç¤ºä¾‹ 5: é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆ8bit å’Œ 16bitï¼‰
        example_training(bitwidth=8)
        example_training(bitwidth=16)
        
        # ç¤ºä¾‹ 6: æ ¡å‡†æ–¹æ³•é€‰æ‹©
        example_calibration_method()
        
        # ç¤ºä¾‹ 7: åŒå‘ GRU
        example_bidirectional()
        
        # ç¤ºä¾‹ 8: ONNX å¯¼å‡º
        example_onnx_export()
        
        # ç¤ºä¾‹ 9: ONNX å¯¼å‡ºå­æ¨¡å¼å¯¹æ¯”
        example_onnx_export_modes()
        
        print("\n" + "=" * 60)
        print("  æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

