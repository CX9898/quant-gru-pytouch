#include <cublas_v2.h>
#include <cuda_fp16.h>
#include <cuda_runtime_api.h>
#include <vector>

#include "blas.h"
#include "devVector.h"
#include "device_ptr.h"
#include "gru_quant.h"
#include "quantize_bitwidth_config.hpp"
#include "quantize_ops.cuh"
#include "quantize_ops_helper.hpp"

namespace kernel {

//#define USE_Piecewise_linear_quantization

template<typename QuantT>
__device__ __forceinline__ QuantT computeZ(// æ›´æ–°é—¨z
    const int channel_idx,
    const int32_t Wx_val,// Wx å¯¹åº”é—¨çš„å€¼
    const int32_t Rh_val,// Rh å¯¹åº”é—¨çš„å€¼
    const int32_t W_sum_mul_x_zp,
    const int32_t R_sum_mul_h_zp,
    const int32_t bx_val,// bx å¯¹åº”é—¨çš„bias
    const int32_t br_val,// br å¯¹åº”é—¨çš„bias
    const QuantGRUReScale &rescale_params) {
    // z = sigmoid(Wx[z_idx] + Rh[z_idx] + bx[bz_idx] + br[bz_idx]);

    // TODO: ä¼˜åŒ–è®¡ç®—
    const int32_t Wx =
        rshift_round(Wx_val - W_sum_mul_x_zp, rescale_params.n_W_mul_x_div_Wx_[channel_idx]) + rescale_params.zp_Wx_;
    const int32_t Rh =
        rshift_round(Rh_val - R_sum_mul_h_zp, rescale_params.n_R_mul_h_div_Rh_[channel_idx]) + rescale_params.zp_Rh_;

    // scale_z_preæ˜¯é€šè¿‡æ•ˆéªŒé˜¶æ®µå¾—åˆ°çš„; é€šè¿‡sigmoidå‡½æ•°å…¥å£å‰çš„å„é¡¹ç›¸åŠ :Wx_val+Rh_val+bx_val+br_valçš„ç»“æœçš„çš„æœ€å¤§æœ€å°å€¼è®¡ç®—å¾—åˆ°

    const int32_t Wx_shifted = rshift_round(Wx - rescale_params.zp_Wx_,
                                            rescale_params.exp2_inv_Wx_div_z_pre_);// nä¸º: scale_Wx / scale_z_pre â‰ˆ 2^-n
    const int32_t Rh_shifted = rshift_round(Rh - rescale_params.zp_Rh_,
                                            rescale_params.exp2_inv_Rh_div_z_pre_);// nä¸º: scale_Rh / scale_z_pre â‰ˆ 2^-n
    const int32_t bx_shifted =
        rshift_round(bx_val, rescale_params.n_bx_div_z_[channel_idx]);// nä¸º: scale_bx / scale_z_pre â‰ˆ 2^-n; bxä¸ºXçš„åç½®
    const int32_t br_shifted =
        rshift_round(br_val, rescale_params.n_br_div_z_[channel_idx]);// nä¸º: scale_br / scale_z_pre â‰ˆ 2^-n; brä¸ºRçš„åç½®

    const int32_t z_pre_i32 = Wx_shifted + Rh_shifted + bx_shifted + br_shifted + rescale_params.zp_z_pre_;

    const QuantT z_pre_i8 = dev::clamp<QuantT>(z_pre_i32);           // clamp: æˆªæ–­åˆ°int8çš„èŒƒå›´
    QuantT z = dev::sigmoid_int8_lut(z_pre_i8, d_sigmoid_int8_z_lut);// TODO: æ”¯æŒint16é‡åŒ–

#ifdef USE_Piecewise_linear_quantization
    // TODO: åˆ†æ®µçº¿æ€§é‡åŒ–
    if constexpr (std::is_same_v<QuantT, int16_t>) {
        // INT16 ç‰ˆæœ¬ï¼šä½¿ç”¨åˆ†æ®µçº¿æ€§æ‹Ÿåˆï¼ˆz é—¨ï¼‰
        // z_pre_i32 å·²ç»åŒ…å«äº† zero-pointï¼Œæ˜¯é‡åŒ–åçš„å€¼ï¼ˆæ— ç¬¦å·åŸŸï¼‰
        uint16_t q_x = static_cast<uint16_t>(max(0, min(65535, z_pre_i32)));
        uint16_t q_y = dev::sigmoid_piecewise_linear_int16(q_x, d_sigmoid_z_lut_int16);
        // è¾“å‡º q_y å·²ç»æ˜¯ uint16_tï¼Œç›´æ¥è½¬æ¢
        z = static_cast<QuantT>(q_y);
    } else {
        // INT8 ç‰ˆæœ¬ï¼šä½¿ç”¨åˆ†æ®µçº¿æ€§æ‹Ÿåˆï¼ˆz é—¨ï¼‰
        // z_pre_i32 å·²ç»åŒ…å«äº† zero-pointï¼Œæ˜¯é‡åŒ–åçš„å€¼ï¼ˆæ— ç¬¦å·åŸŸï¼‰
        // ğŸ”¥ ä¿®å¤ï¼šç›´æ¥è½¬æ¢ä¸º uint8_tï¼Œè€Œä¸æ˜¯å…ˆè½¬æ¢ä¸º int8_t
        uint8_t q_x = static_cast<uint8_t>(max(0, min(255, z_pre_i32)));
        uint8_t q_y = dev::sigmoid_piecewise_linear_int8(q_x, d_sigmoid_z_lut_int8);
        // è¾“å‡º q_y å·²ç»æ˜¯ uint8_tï¼Œç›´æ¥è½¬æ¢
        z = static_cast<QuantT>(q_y);
    }
#endif

//     const int row = blockDim.x * blockIdx.x + threadIdx.x; // å½“å‰çº¿ç¨‹å¯¹åº”çš„éšè—å•å…ƒ
//     const int col = blockDim.y * blockIdx.y + threadIdx.y; // å½“å‰çº¿ç¨‹å¯¹åº”çš„batchæ ·æœ¬
//     const int weight_idx = col * (rescale_params.test.hidden_ * 3) + row; // ç”¨äºè®¿é—® [Wx, Rh] çš„å±•å¼€ç´¢å¼•
//     if (weight_idx == 1) {
//         float Wx_fp = dequantize(Wx, rescale_params.test.exp2_inv_Wx_, rescale_params.zp_Wx_);
//         float Rh_fp = dequantize(Rh, rescale_params.test.exp2_inv_Rh_, rescale_params.zp_Rh_);
//         float bx_fp = dequantize(bx_val, rescale_params.test.exp2_inv_bx_dev_[channel_idx], 0);
//         float br_fp = dequantize(br_val, rescale_params.test.exp2_inv_br_dev_[channel_idx], 0);
//         float z_pre_fp = dequantize(z_pre_i8, rescale_params.test.exp2_inv_z_pre_, rescale_params.zp_z_pre_);
//         float Wx_shifted_fp = dequantize(Wx_shifted,
//                                                 rescale_params.exp2_inv_Wx_div_z_pre_,
//                                                 rescale_params.zp_Wx_);
//         float Rh_shifted_fp = dequantize(Rh_shifted,
//                                                 rescale_params.exp2_inv_Rh_div_z_pre_,
//                                                 rescale_params.zp_Rh_);
//         float bx_shifted_fp = dequantize(bx_shifted, rescale_params.n_bx_div_z_[channel_idx], 0);
//         float br_shifted_fp = dequantize(br_shifted, rescale_params.n_br_div_z_[channel_idx], 0);
//         float z_fp = dequantize(z, rescale_params.test.exp2_inv_z_out_, rescale_params.test.zp_z_out_);
//         printf("quant haste computeZ: "
//                "Wx_fp=%f, Rh_fp=%f, bx_fp=%f, br_fp=%f, z_pre_fp=%f, z_out_fp=%f "
//                "Wx_q = %d, "
//                "Rh_q = %d, "
//                "z_pre_i32_q = %d, "
//                "z_pre_i8_q = %d, "
//                "z_out_q = %d"
//                "\n",
//                Wx_fp, Rh_fp, bx_fp, br_fp, z_pre_fp, z_fp,
//                Wx, Rh, z_pre_i32, z_pre_i8, z);
//     }


    return z;
}

template<typename QuantT>
__device__ __forceinline__ QuantT computeR(// é‡ç½®é—¨r
    const int channel_idx,
    const int32_t Wx_val,// Wx å¯¹åº”é—¨çš„å€¼
    const int32_t Rh_val,// Rh å¯¹åº”é—¨çš„å€¼
    const int32_t W_sum_mul_x_zp,
    const int32_t R_sum_mul_h_zp,
    const int32_t bx_val,// bx å¯¹åº”é—¨çš„bias
    const int32_t br_val,// br å¯¹åº”é—¨çš„bias
    const QuantGRUReScale &rescale_params) {
    // r = sigmoid(Wx[r_idx] + Rh[r_idx] + bx[br_idx] + br[br_idx]);

    // nä¸º: (scale_W * scale_x) / scale_Wx â‰ˆ 2^-n
    const int32_t Wx =
        rshift_round(Wx_val - W_sum_mul_x_zp, rescale_params.n_W_mul_x_div_Wx_[channel_idx]) + rescale_params.zp_Wx_;
    // nä¸º: (scale_R * scale_h) / scale_Rh â‰ˆ 2^-n
    const int32_t Rh =
        rshift_round(Rh_val - R_sum_mul_h_zp, rescale_params.n_R_mul_h_div_Rh_[channel_idx]) + rescale_params.zp_Rh_;

    const int32_t Wx_shifted = rshift_round(Wx - rescale_params.zp_Wx_,
                                            rescale_params.exp2_inv_Wx_div_r_pre_);// nä¸º: scale_Wx / scale_r_pre â‰ˆ 2^-n
    const int32_t Rh_shifted = rshift_round(Rh - rescale_params.zp_Rh_,
                                            rescale_params.exp2_inv_Rh_div_r_pre_);// nä¸º: scale_Rh / scale_r_pre â‰ˆ 2^-n
    const int32_t bx_shifted =
        rshift_round(bx_val, rescale_params.n_bx_div_r_[channel_idx]);// nä¸º: scale_bx / scale_r_pre â‰ˆ 2^-n; bxä¸ºXçš„åç½®
    const int32_t br_shifted =
        rshift_round(br_val, rescale_params.n_br_div_r_[channel_idx]);// nä¸º: scale_br / scale_r_pre â‰ˆ 2^-n; brä¸ºRçš„åç½®

    // scale_z_preæ˜¯é€šè¿‡æ•ˆéªŒé˜¶æ®µå¾—åˆ°çš„; é€šè¿‡sigmoidå‡½æ•°å…¥å£å‰çš„å„é¡¹ç›¸åŠ :Wx_val+Rh_val+bx_val+br_valçš„ç»“æœçš„çš„æœ€å¤§æœ€å°å€¼è®¡ç®—å¾—åˆ°
    const int32_t r_pre_i32 = Wx_shifted + Rh_shifted + bx_shifted + br_shifted + rescale_params.zp_r_pre_;

    const QuantT r_pre_i8 = dev::clamp<QuantT>(r_pre_i32);           // clamp: æˆªæ–­åˆ°int8çš„èŒƒå›´
    QuantT r = dev::sigmoid_int8_lut(r_pre_i8, d_sigmoid_int8_r_lut);// TODO: æ”¯æŒint16é‡åŒ–

#ifdef USE_Piecewise_linear_quantization
    // TODO: åˆ†æ®µçº¿æ€§é‡åŒ–
    if constexpr (std::is_same_v<QuantT, int16_t>) {
        // INT16 ç‰ˆæœ¬ï¼šä½¿ç”¨åˆ†æ®µçº¿æ€§æ‹Ÿåˆï¼ˆr é—¨ï¼‰
        // r_pre_i32 å·²ç»åŒ…å«äº† zero-pointï¼Œæ˜¯é‡åŒ–åçš„å€¼ï¼ˆæ— ç¬¦å·åŸŸï¼‰
        uint16_t q_x = static_cast<uint16_t>(max(0, min(65535, r_pre_i32)));
        uint16_t q_y = dev::sigmoid_piecewise_linear_int16(q_x, d_sigmoid_r_lut_int16);
        // è¾“å‡º q_y å·²ç»æ˜¯ uint16_tï¼Œç›´æ¥è½¬æ¢
        r = static_cast<QuantT>(q_y);
    } else {
        // INT8 ç‰ˆæœ¬ï¼šä½¿ç”¨åˆ†æ®µçº¿æ€§æ‹Ÿåˆï¼ˆr é—¨ï¼‰
        // r_pre_i32 å·²ç»åŒ…å«äº† zero-pointï¼Œæ˜¯é‡åŒ–åçš„å€¼ï¼ˆæ— ç¬¦å·åŸŸï¼‰
        // ğŸ”¥ ä¿®å¤ï¼šç›´æ¥è½¬æ¢ä¸º uint8_tï¼Œè€Œä¸æ˜¯å…ˆè½¬æ¢ä¸º int8_t
        uint8_t q_x = static_cast<uint8_t>(max(0, min(255, r_pre_i32)));
        uint8_t q_y = dev::sigmoid_piecewise_linear_int8(q_x, d_sigmoid_r_lut_int8);
        // è¾“å‡º q_y å·²ç»æ˜¯ uint8_tï¼Œç›´æ¥è½¬æ¢
        r = static_cast<QuantT>(q_y);
    }
#endif

//        const int row = blockDim.x * blockIdx.x + threadIdx.x; // å½“å‰çº¿ç¨‹å¯¹åº”çš„éšè—å•å…ƒ
//        const int col = blockDim.y * blockIdx.y + threadIdx.y; // å½“å‰çº¿ç¨‹å¯¹åº”çš„batchæ ·æœ¬
//        const int weight_idx = col * (rescale_params.test.hidden_ * 3) + row; // ç”¨äºè®¿é—® [Wx, Rh] çš„å±•å¼€ç´¢å¼•
//        if (weight_idx == 0) {
//            float Wx_fp = dequantize(Wx, rescale_params.test.exp2_inv_Wx_, rescale_params.zp_Wx_);
//            float Rh_fp = dequantize(Rh, rescale_params.test.exp2_inv_Rh_, rescale_params.zp_Rh_);
//            float bx_fp = dequantize(bx_val, rescale_params.test.exp2_inv_bx_dev_[channel_idx], 0);
//            float br_fp = dequantize(br_val, rescale_params.test.exp2_inv_br_dev_[channel_idx], 0);
//            float r_pre_fp = dequantize(r_pre_i8, rescale_params.test.exp2_inv_r_pre_, rescale_params.zp_r_pre_);
//            float Wx_shifted_fp = dequantize(Wx_shifted,
//                                                    rescale_params.exp2_inv_Wx_div_r_pre_,
//                                                    rescale_params.zp_Wx_);
//            float Rh_shifted_fp = dequantize(Rh_shifted,
//                                                    rescale_params.exp2_inv_Rh_div_r_pre_,
//                                                    rescale_params.zp_Rh_);
//            float bx_shifted_fp = dequantize(bx_shifted, rescale_params.n_bx_div_r_[channel_idx], 0);
//            float br_shifted_fp = dequantize(br_shifted, rescale_params.n_br_div_r_[channel_idx], 0);
//            float r_fp = dequantize(r, rescale_params.test.exp2_inv_r_out_, rescale_params.test.zp_r_out_);
//            printf(
//                "quant haste compute R: Wx_fp=%f, Rh_fp=%f, bx_fp=%f, br_fp=%f, r_pre_fp=%f, r_fp=%f "
//                "Wx_shifted_fp=%f, Rh_shifted_fp=%f, bx_shifted_fp=%f, br_shifted_fp=%f\n",
//                Wx_fp,
//                Rh_fp,
//                bx_fp,
//                br_fp,
//                r_pre_fp,
//                r_fp,
//                Wx_shifted_fp,
//                Rh_shifted_fp,
//                bx_shifted_fp,
//                br_shifted_fp);
//        }

    return r;
}

template<typename GT,    // å€™é€‰çŠ¶æ€ g è¾“å‡ºçš„ç±»å‹
         typename RT>    // é‡ç½®é—¨ r çš„ç±»å‹
__device__ __forceinline__ GT computeG(// New Gate
    const int channel_idx,
    const int32_t Wx_val,// Wx å¯¹åº”é—¨çš„å€¼
    const int32_t Rh_val,// Rh å¯¹åº”é—¨çš„å€¼
    const int32_t W_sum_mul_x_zp,
    const int32_t R_sum_mul_h_zp,
    const int32_t bx_val,// bx å¯¹åº”é—¨çš„bias
    const int32_t br_val,// br å¯¹åº”é—¨çš„bias
    const RT r,
    const QuantGRUReScale &rescale_params) {
    //  g = tanh (Wx[g_idx] + r * (Rh[g_idx] + br[bg_idx]) + bx[bg_idx]);

    const int32_t Wx =
        rshift_round(Wx_val - W_sum_mul_x_zp, rescale_params.n_W_mul_x_div_Wx_[channel_idx]) + rescale_params.zp_Wx_;
    const int32_t Rh =
        rshift_round(Rh_val - R_sum_mul_h_zp, rescale_params.n_R_mul_h_div_Rh_[channel_idx]) + rescale_params.zp_Rh_;
    const int32_t Rh_add_br_g = rshift_round(Rh - rescale_params.zp_Rh_, rescale_params.n_Rh_div_Rh_add_br_) +
                                rshift_round(br_val, rescale_params.n_br_div_Rh_add_br_[channel_idx]) +
                                rescale_params.zp_Rh_add_br_;

    const int32_t rRh = rshift_round(
                            (r - rescale_params.zp_r_out_) * (Rh_add_br_g - rescale_params.zp_Rh_add_br_),
                            rescale_params.n_r_mul_Rh_add_br_div_rRh_) +
                        rescale_params.zp_rRh_;

    const int32_t Wx_shifted = rshift_round(Wx - rescale_params.zp_Wx_, rescale_params.n_Wx_div_g_pre_);
    const int32_t rRh_shifted = rshift_round(rRh - rescale_params.zp_rRh_, rescale_params.n_rRh_div_g_pre_);
    const int32_t bx_shifted = rshift_round(bx_val, rescale_params.exp2_inv_bx_div_g_pre_[channel_idx]);

    // ç´¯åŠ æ±‚å’Œ
    const int32_t g_pre_i32 = Wx_shifted + rRh_shifted + bx_shifted + rescale_params.zp_g_pre_;

    const GT g_pre_i8 = dev::clamp<GT>(g_pre_i32);         // æˆªæ–­åˆ°int8
    GT g = dev::tanh_int8_lut(g_pre_i8, d_tanh_int8_g_lut);// TODO: æ”¯æŒint16é‡åŒ–

#ifdef USE_Piecewise_linear_quantization
    // TODO: åˆ†æ®µçº¿æ€§é‡åŒ–
    if constexpr (std::is_same_v<GT, int16_t>) {
        // INT16 ç‰ˆæœ¬ï¼šä½¿ç”¨åˆ†æ®µçº¿æ€§æ‹Ÿåˆ
        // g_pre_i32 å·²ç»åŒ…å«äº† zero-pointï¼Œæ˜¯é‡åŒ–åçš„å€¼ï¼ˆæ— ç¬¦å·åŸŸï¼‰
        uint16_t q_x = static_cast<uint16_t>(max(0, min(65535, g_pre_i32)));
        uint16_t q_y = dev::tanh_piecewise_linear_int16(q_x, d_tanh_lut_int16);
        // è¾“å‡º q_y å·²ç»æ˜¯ uint16_tï¼Œç›´æ¥è½¬æ¢
        g = static_cast<GT>(q_y);
    } else {
        // INT8 ç‰ˆæœ¬ï¼šä½¿ç”¨åˆ†æ®µçº¿æ€§æ‹Ÿåˆ
        // g_pre_i32 å·²ç»åŒ…å«äº† zero-pointï¼Œæ˜¯é‡åŒ–åçš„å€¼ï¼ˆæ— ç¬¦å·åŸŸï¼‰
        // ğŸ”¥ ä¿®å¤ï¼šç›´æ¥è½¬æ¢ä¸º uint8_tï¼Œè€Œä¸æ˜¯å…ˆè½¬æ¢ä¸º int8_t
        uint8_t q_x = static_cast<uint8_t>(max(0, min(255, g_pre_i32)));
        uint8_t q_y = dev::tanh_piecewise_linear_int8(q_x, d_tanh_lut_int8);
        // è¾“å‡º q_y å·²ç»æ˜¯ uint8_tï¼Œç›´æ¥è½¬æ¢
        g = static_cast<GT>(q_y);
    }
#endif

    //    const int row = blockDim.x * blockIdx.x + threadIdx.x; // å½“å‰çº¿ç¨‹å¯¹åº”çš„éšè—å•å…ƒ
    //    const int col = blockDim.y * blockIdx.y + threadIdx.y; // å½“å‰çº¿ç¨‹å¯¹åº”çš„batchæ ·æœ¬
    //    const int weight_idx = col * (rescale_params.test.hidden_ * 3) + row; // ç”¨äºè®¿é—® [Wx, Rh] çš„å±•å¼€ç´¢å¼•
    //    if (weight_idx == 0) {
    //        float Wx_fp = dequant_from_exp2(Wx, rescale_params.test.exp2_inv_Wx_, rescale_params.zp_Wx_);
    //        float Rh_fp = dequant_from_exp2(Rh, rescale_params.test.exp2_inv_Rh_, rescale_params.zp_Rh_);
    //        float bx_fp = dequant_from_exp2(bx_val, rescale_params.test.exp2_inv_bx_dev_[channel_idx], 0);
    //        float br_fp = dequant_from_exp2(br_val, rescale_params.test.exp2_inv_br_dev_[channel_idx], 0);
    //        float g_pre_fp = dequant_from_exp2(g_pre_i8, rescale_params.test.exp2_inv_g_pre_, rescale_params.zp_g_pre_);
    //        float g_fp = dequant_from_exp2(g, rescale_params.test.exp2_inv_g_out_, rescale_params.test.zp_g_out_);
    //        printf(
    //            "quant haste computeG: Wx_fp=%f, Rh_fp=%f, bx_fp=%f, br_fp=%f, g_pre_fp=%f, ",
    //            Wx_fp,
    //            Rh_fp,
    //            bx_fp,
    //            br_fp,
    //            g_pre_fp);
    //        printf(""
    //               "Wx_val = %d, "
    //               "W_sum_mul_x_zp = %d, "
    //               "Wx = %d, "
    //               "Rh_val = %d, "
    //               "R_sum_mul_h_zp = %d, "
    //               "Rh = %d, "
    //               "bx_val = %d, "
    //               "br_val = %d, "
    //               "Wx_shifted=%d, rRh_shifted=%d, bx_shifted=%d, "
    //               "g_pre_i32 = %d, "
    //               "g_pre_i8 = %d, "
    //               "g = %d, "
    //               "g_pre_fp = %f, "
    //               "g_fp = %f"
    //               "\n",
    //               Wx_val, W_sum_mul_x_zp, Wx, Rh_val, R_sum_mul_h_zp, Rh, bx_val, br_val,
    //               Wx_shifted, rRh_shifted, bx_shifted, g_pre_i32, g_pre_i8, g, g_pre_fp, g_fp);
    //    }

    return g;
}

template<typename ZT,      // æ›´æ–°é—¨ z çš„ç±»å‹
         typename GT,      // å€™é€‰çŠ¶æ€ g çš„ç±»å‹
         typename HT>      // éšè—çŠ¶æ€çš„ç±»å‹ï¼ˆè¾“å…¥è¾“å‡ºç›¸åŒï¼‰
__device__ __forceinline__ HT computeH(// æœ€ç»ˆh
    const ZT z,
    const GT g,
    const HT h_old,
    const QuantGRUReScale &rescale_params) {
    // cur_h_value = z * h[output_idx] + (1.0 - z) * g;

    const int32_t old_contrib = rshift_round((z - rescale_params.zp_z_out_) * (h_old - rescale_params.zp_h_),
                                             rescale_params.n_z_mul_h_div_old_contrib_) +
                                rescale_params.zp_old_contrib_;

    const int32_t one_minus_update = rescale_params.one_div_one_minus_update_ -
                                     rshift_round(z - rescale_params.zp_z_out_,
                                                  rescale_params.n_z_out_div_one_minus_update_) +
                                     rescale_params.zp_one_minus_update_;
    const int32_t new_contrib =
        rshift_round((one_minus_update - rescale_params.zp_one_minus_update_) * (g - rescale_params.zp_g_out_),
                     rescale_params.n_one_minus_update_mul_g_div_new_contrib_) +
        rescale_params.zp_new_contrib_;
    const int32_t h_i32 =
        rshift_round(old_contrib - rescale_params.zp_old_contrib_, rescale_params.n_old_contrib_div_h_) +
        rshift_round(new_contrib - rescale_params.zp_new_contrib_, rescale_params.n_new_contrib_div_h_) +
        rescale_params.zp_h_;

    const HT h = dev::clamp<HT>(h_i32);

    // const int row = blockDim.x * blockIdx.x + threadIdx.x; // å½“å‰çº¿ç¨‹å¯¹åº”çš„éšè—å•å…ƒ
    // const int col = blockDim.y * blockIdx.y + threadIdx.y; // å½“å‰çº¿ç¨‹å¯¹åº”çš„batchæ ·æœ¬
    // const int weight_idx = col * (rescale_params.test.hidden_ * 3) + row; // ç”¨äºè®¿é—® [Wx, Rh] çš„å±•å¼€ç´¢å¼•
    // if (weight_idx == 1) {
    //     float z_fp = dequant_from_exp2(z, rescale_params.test.exp2_inv_z_out_, rescale_params.zp_z_out_);
    //     float g_fp = dequant_from_exp2(g, rescale_params.test.exp2_inv_g_out_, rescale_params.zp_g_out_);
    //     float h_old_fp = dequant_from_exp2(h_old, rescale_params.test.exp2_inv_h_, rescale_params.zp_h_);
    //     float old_contrib_fp = dequant_from_exp2(old_contrib, rescale_params.test.exp2_inv_old_contrib_,
    //                                              rescale_params.test.zp_old_contrib_);
    //     float one_minus_update_fp = dequant_from_exp2(one_minus_update,
    //                                                   rescale_params.test.exp2_inv_one_minus_update_,
    //                                                   rescale_params.zp_one_minus_update_);
    //     float new_contrib_fp = dequant_from_exp2(new_contrib,
    //                                              rescale_params.test.exp2_inv_new_contrib_,
    //                                              rescale_params.test.zp_new_contrib_);
    //     float h_fp = dequant_from_exp2(h, rescale_params.test.exp2_inv_h_, rescale_params.test.zp_h_);
    //     printf("quant haste computeH: "
    //            "z_q = %d, "
    //            "g_q = %d, "
    //            "h_old_q = %d, "
    //            "old_contrib_q = %d, "
    //            "one_minus_update_q = %d, "
    //            "new_contrib_q = %d, "
    //            "h_q = %d, "
    //            " z_fp=%f, g_fp=%f, h_old_fp=%f, old_contrib_fp=%f, one_minus_update_fp=%f, new_contrib_fp=%f, h_fp=%f\n",
    //            z, g, h_old, old_contrib, one_minus_update, new_contrib, h,
    //            z_fp,
    //            g_fp,
    //            h_old_fp,
    //            old_contrib_fp,
    //            one_minus_update_fp,
    //            new_contrib_fp,
    //            h_fp);
    // }

    return h;
}

// x : éå¯¹ç§°é‡åŒ–, scaleåˆ†æ—¶é—´æ­¥ä¸åŒ
// W : å¯¹ç§°é‡åŒ–, scaleåˆ†ä¸ºä¸‰ä¸ªé—¨, åˆ†ä¸º
// R : å¯¹ç§°é‡åŒ–, scaleåˆ†ä¸ºä¸‰ä¸ªé—¨
// bx : å¯¹ç§°é‡åŒ–, scaleåˆ†ä¸ºä¸‰ä¸ªé—¨
// br : å¯¹ç§°é‡åŒ–, scaleåˆ†ä¸ºä¸‰ä¸ªé—¨
// h : å¯¹ç§°é‡åŒ–, scaleåˆ†æ—¶é—´æ­¥ä¸åŒ
//
// C = input_size(è¾“å…¥ç»´åº¦), H = hidden_size(éšè—å±‚ç»´åº¦),
// T = time_steps(æ—¶é—´æ­¥), N = batch_size(æ‰¹é‡å¤§å°)
template<typename ZT,           // æ›´æ–°é—¨ z çš„ç±»å‹
         typename RT,           // é‡ç½®é—¨ r çš„ç±»å‹
         typename GT,           // å€™é€‰çŠ¶æ€ g çš„ç±»å‹
         typename HT,           // éšè—çŠ¶æ€ h çš„ç±»å‹ï¼ˆè¾“å…¥å’Œè¾“å‡ºç›¸åŒï¼‰
         typename VT,           // å†…éƒ¨åˆ†é‡ v çš„ç±»å‹
         bool Training, bool ApplyZoneout>
__global__ void PointwiseOperationsQuant(
    const int batch_dim,                   // æ‰¹é‡å¤§å°
    const int hidden_dim,                  // éšè—å•å…ƒæ•°
    const int32_t *Wx,                     // å‰å‘çŸ©é˜µä¹˜W * x, åŒ…å«Wz, Wr, Wh
    const int32_t *Rh,                     // å‰å‘çŸ©é˜µä¹˜R * h, åŒ…å«Rz, Rr, Rh
    const int32_t *W_sum_mul_x_zp,         // hidden_size * 3
    const int32_t *R_sum_mul_h_zp,         // hidden_size * 3
    const int32_t *bx,                     // è¾“å…¥åç½®, åŒ…å«bz, br, bh
    const int32_t *br,                     // éšè—åç½®, åŒ…å«bz, br, bh
    const HT *h,                           // ä¸Šä¸€æ—¶é—´æ­¥éšè—çŠ¶æ€
    HT *h_out,                             // å½“å‰æ—¶é—´æ­¥éšè—çŠ¶æ€
    VT *v,                                 // ä¿å­˜å†…éƒ¨åˆ†é‡ç”¨äºåå‘ä¼ æ’­
    const float zoneout_prob,              // Zoneoutæ¦‚ç‡
    const HT *zoneout_mask,                // Zoneout mask (only used if ApplyZoneout==true)
    const QuantGRUReScale rescale_params) {

    /* è®¡ç®—ç´¢å¼• */
    const int row = blockDim.x * blockIdx.x + threadIdx.x;// å½“å‰çº¿ç¨‹å¯¹åº”çš„éšè—å•å…ƒ
    const int col = blockDim.y * blockIdx.y + threadIdx.y;// å½“å‰çº¿ç¨‹å¯¹åº”çš„batchæ ·æœ¬

    if (row >= hidden_dim || col >= batch_dim) return;// è¾¹ç¼˜åˆ¤æ–­

    const int weight_idx = col * (hidden_dim * 3) + row;// ç”¨äºè®¿é—® [Wx, Rh] çš„å±•å¼€ç´¢å¼•

    // Index into the `h` and `h_out` vectors (they have a stride of
    // `hidden_dim`).
    const int output_idx = col * hidden_dim + row;

    // Indicies into the Wx and Rh matrices (for each of the u, r, and e
    // components).
    const int z_idx = weight_idx + 0 * hidden_dim;
    const int r_idx = weight_idx + 1 * hidden_dim;
    const int g_idx = weight_idx + 2 * hidden_dim;

    // Indices into the bias vectors (for each of the u, r, and e components).
    const int b_z_idx = row + 0 * hidden_dim;// æ›´æ–°é—¨å¯¹åº”ç´¢å¼•
    const int b_r_idx = row + 1 * hidden_dim;// é‡ç½®é—¨å¯¹åº”ç´¢å¼•
    const int b_g_idx = row + 2 * hidden_dim;// å€™é€‰çŠ¶æ€å¯¹åº”ç´¢å¼•

    /* GRUå‰å‘è®¡ç®— */

    const ZT z = computeZ<ZT>(b_z_idx,
                              Wx[z_idx],
                              Rh[z_idx],
                              W_sum_mul_x_zp[b_z_idx],
                              R_sum_mul_h_zp[b_z_idx],
                              bx[b_z_idx],
                              br[b_z_idx],
                              rescale_params);// æ›´æ–°é—¨z

    const RT r = computeR<RT>(b_r_idx,
                              Wx[r_idx],
                              Rh[r_idx],
                              W_sum_mul_x_zp[b_r_idx],
                              R_sum_mul_h_zp[b_r_idx],
                              bx[b_r_idx],
                              br[b_r_idx],
                              rescale_params);// é‡ç½®é—¨r

    const GT g = computeG<GT, RT>(b_g_idx,
                                  Wx[g_idx],
                                  Rh[g_idx],
                                  W_sum_mul_x_zp[b_g_idx],
                                  R_sum_mul_h_zp[b_g_idx],
                                  bx[b_g_idx],
                                  br[b_g_idx],
                                  r,
                                  rescale_params);// New Gate
    // å€™é€‰çŠ¶æ€~ht


    /* è®­ç»ƒæ¨¡å¼ */
    // Store internal activations if we're eventually going to backprop.
    if (Training) {
        const int base_v_idx = col * (hidden_dim * 4) + row;
        v[base_v_idx + 0 * hidden_dim] = static_cast<VT>(z);
        v[base_v_idx + 1 * hidden_dim] = static_cast<VT>(r);
        v[base_v_idx + 2 * hidden_dim] = static_cast<VT>(g);
        const VT Rh_add_br_g = rshift_round(Rh[g_idx] - rescale_params.zp_Rh_, rescale_params.n_Rh_div_Rh_add_br_) +
                               rshift_round(br[b_g_idx], rescale_params.n_br_div_Rh_add_br_[b_g_idx]) +
                               rescale_params.zp_Rh_add_br_;

        v[base_v_idx + 3 * hidden_dim] = Rh_add_br_g;
    }

    HT cur_h_value = computeH<ZT, GT, HT>(z, g, h[output_idx], rescale_params);

    /* å¯ç”¨Zoneout, å¯¹GRU éšè—çŠ¶æ€çš„éšæœºä¿ç•™ */
    // TODO: æ”¯æŒé‡åŒ–
    //    if (ApplyZoneout) {
    //        if (Training) {
    //            cur_h_value = (cur_h_value - h[output_idx]) * zoneout_mask[output_idx] +
    //                          h[output_idx];
    //        } else {
    //            cur_h_value = (zoneout_prob * h[output_idx]) +
    //                          ((static_cast<T>(1.0) - zoneout_prob) * cur_h_value);
    //        }
    //    }

    /* ç»“æœå‚¨å­˜ */
    h_out[output_idx] = cur_h_value;
}

//#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ < 700)
//
//template<typename T, bool Training, bool ApplyZoneout>
//__global__ void PointwiseOperations(const int batch_dim, const int hidden_dim,
//                                    const half *Wx, const half *Rh,
//                                    const half *bx, const half *br,
//                                    const half *h, half *h_out, half *v,
//                                    const half zoneout_prob,
//                                    const half *zoneout_mask) {
//    device_assert_fail("FP16 is not supported on compute capability < 7.0.");
//}
//
//#endif

}// namespace kernel


namespace gru {

template<typename T>
struct ForwardPassQuant<T>::private_data {
    bool training;
    int batch_size;
    int input_size;
    int hidden_size;
    cublasHandle_t blas_handle;
    cudaStream_t stream[2];
    cudaEvent_t event;
    cudaStream_t sync_stream;
};

template<typename T>
ForwardPassQuant<T>::ForwardPassQuant(const bool training, const int batch_size,
                                      const int input_size, const int hidden_size,
                                      const cublasHandle_t &blas_handle,
                                      const cudaStream_t &stream)
    : data_(new private_data) {
    data_->training = training;
    data_->batch_size = batch_size;
    data_->input_size = input_size;
    data_->hidden_size = hidden_size;
    data_->blas_handle = blas_handle;
    data_->sync_stream = stream;
    cudaStreamCreate(&data_->stream[0]);
    cudaStreamCreate(&data_->stream[1]);
    cudaEventCreateWithFlags(&data_->event, cudaEventDisableTiming);
}

template<typename T>
ForwardPassQuant<T>::~ForwardPassQuant() {
    if (data_->sync_stream) {
        cudaEventRecord(data_->event, data_->stream[1]);
        cudaStreamWaitEvent(data_->sync_stream, data_->event, 0);
        cudaEventRecord(data_->event, data_->stream[0]);
        cudaStreamWaitEvent(data_->sync_stream, data_->event, 0);
    } else {
        cudaStreamSynchronize(data_->stream[1]);
        cudaStreamSynchronize(data_->stream[0]);
    }
    cudaEventDestroy(data_->event);
    cudaStreamDestroy(data_->stream[1]);
    cudaStreamDestroy(data_->stream[0]);
    delete data_;
}

template<typename T>
void ForwardPassQuant<T>::Iterate(const T *W,       // [C,H*3]
                                  const T *R,       // [H,H*3]
                                  const int32_t *bx,// [H*3]
                                  const int32_t *br,// [H*3]
                                  const T *x,       // [N,C]
                                  const T *h,       // [N,H]
                                  T *h_out,         // [N,H]
                                  T *v,             // [N,H*4]
                                  int32_t *tmp_Wx,  // [N,H*3]
                                  int32_t *tmp_Rh,  // [N,H*3]
                                  const float zoneout_prob,
                                  const T *zoneout_mask// Zoneout mask [N,H]
) {
    // TODO : æ”¯æŒé‡åŒ–
    //    using alpha_beta_t = std::conditional_t<
    //        std::is_same_v<T, int8_t> || std::is_same_v<T, int16_t>,
    //        int,
    //        T>;
    //
    //    static const alpha_beta_t alpha = static_cast<alpha_beta_t>(1);
    //    static const alpha_beta_t beta = static_cast<alpha_beta_t>(0);
    //
    //    const blas<void>::set_pointer_mode scoped1(data_->blas_handle);
    //
    //    const int batch_size = data_->batch_size;
    //    const int input_size = data_->input_size;
    //    const int hidden_size = data_->hidden_size;
    //    const cublasHandle_t blas_handle = data_->blas_handle;
    //    const cudaStream_t stream2 = data_->stream[1];
    //    const cudaEvent_t event = data_->event;
    //
    //    cudaStream_t save_stream;
    //    cublasGetStream(blas_handle, &save_stream);
    //
    //    cublasSetStream(blas_handle, stream2);
    //    blas<T>::gemm(blas_handle, CUBLAS_OP_N, CUBLAS_OP_N, hidden_size * 3,
    //                  batch_size, input_size, &alpha, W, hidden_size * 3, x,
    //                  input_size, &beta, tmp_Wx, hidden_size * 3);
    //    cudaEventRecord(event, stream2);
    //
    //    IterateInternal(R, bx, br, h, h_out, v, tmp_Wx, tmp_Rh, zoneout_prob,
    //                    zoneout_mask);
    //
    //    cublasSetStream(blas_handle, save_stream);
}

template<typename QuantT>
void ForwardPassQuant<QuantT>::IterateInternal(
    // C = input_size(è¾“å…¥ç»´åº¦), H = hidden_size(éšè—å±‚ç»´åº¦),
    // T = time_steps(æ—¶é—´æ­¥), N = batch_size(æ‰¹é‡å¤§å°)
    const QuantT *R,          // [H,H*3]
    const int32_t *bx,        // [H*3]
    const int32_t *br,        // [H*3]
    const QuantT *h,          // [N,H]
    QuantT *h_out,            // [N,H]
    QuantT *v,                // [N,H*4]
    const int32_t *tmp_Wx,    // [N,H*3]
    int32_t *tmp_Rh,          // [N,H*3]
    const int *W_sum_mul_x_zp,// hidden_size * 3
    const int *R_sum_mul_h_zp,// hidden_size * 3
    const float zoneout_prob,
    const QuantT *zoneout_mask// Zoneout mask [N,H]
) {
    // Constants for GEMM
    static const int32_t alpha = static_cast<int32_t>(1);
    static const int32_t beta = static_cast<int32_t>(0);

    const bool training = data_->training;
    const int batch_size = data_->batch_size;
    const int hidden_size = data_->hidden_size;
    const cublasHandle_t blas_handle = data_->blas_handle;
    const cudaStream_t stream1 = data_->stream[0];
    const cudaEvent_t event = data_->event;

    cublasSetStream(blas_handle, stream1);
    blas<QuantT>::gemm(blas_handle, CUBLAS_OP_N, CUBLAS_OP_N, hidden_size * 3,
                       batch_size, hidden_size, &alpha, R, hidden_size * 3, h,
                       hidden_size, &beta, tmp_Rh, hidden_size * 3);

    // Compute launch configuration for pointwise operations kernel.
    const dim3 blockDim(32, 16);
    const dim3 gridDim((hidden_size + blockDim.x - 1) / blockDim.x,
                       (batch_size + blockDim.y - 1) / blockDim.y);

    cudaStreamWaitEvent(stream1, event, 0);

    // æ ¹æ® bitwidth_config_ é€‰æ‹© kernel æ¨¡æ¿å‚æ•°
    // ä½¿ç”¨æ¨¡å¼åŒ¹é…è€Œéå®Œå…¨å±•å¼€ï¼Œé¿å…æ¨¡æ¿è†¨èƒ€ï¼ˆ5^4 Ã— 4 = 2500 ä¸ªå®ä¾‹ï¼‰
    // åªæ”¯æŒå¸¸ç”¨é…ç½®ï¼šå…¨ INT8ã€å…¨ INT16ã€æ··åˆç²¾åº¦
    const auto& cfg = bitwidth_config_;

    // è¾…åŠ©å®ç®€åŒ– kernel è°ƒç”¨ï¼ˆæ·»åŠ ç±»å‹è½¬æ¢ï¼‰
    // æ¨¡æ¿å‚æ•°: ZT, RT, GT, HT, VT, Training, ApplyZoneout
    #define LAUNCH_KERNEL(ZT, RT, GT, HT, TRAINING, ZONEOUT) \
        kernel::PointwiseOperationsQuant<ZT, RT, GT, HT, HT, TRAINING, ZONEOUT> \
            <<<gridDim, blockDim, 0, stream1>>>( \
            batch_size, hidden_size, tmp_Wx, tmp_Rh, W_sum_mul_x_zp, R_sum_mul_h_zp, bx, br, \
            reinterpret_cast<const HT*>(h), reinterpret_cast<HT*>(h_out), \
            (TRAINING) ? reinterpret_cast<HT*>(v) : nullptr, \
            (ZONEOUT) ? zoneout_prob : 0.0f, \
            (ZONEOUT) ? reinterpret_cast<const HT*>(zoneout_mask) : nullptr, \
            rescale_param_)

    // æ£€æµ‹é…ç½®æ¨¡å¼
    auto isAllInt8 = [&cfg]() {
        return cfg.z_out_bitwidth == QuantBitWidth::INT8 &&
               cfg.r_out_bitwidth == QuantBitWidth::INT8 &&
               cfg.g_out_bitwidth == QuantBitWidth::INT8 &&
               cfg.h_bitwidth == QuantBitWidth::INT8;
    };

    auto isAllInt16 = [&cfg]() {
        return cfg.z_out_bitwidth == QuantBitWidth::INT16 &&
               cfg.r_out_bitwidth == QuantBitWidth::INT16 &&
               cfg.g_out_bitwidth == QuantBitWidth::INT16 &&
               cfg.h_bitwidth == QuantBitWidth::INT16;
    };

    // æ··åˆç²¾åº¦ï¼šé—¨ç”¨ INT8ï¼Œå€™é€‰çŠ¶æ€ç”¨ INT16
    auto isMixedPrecision = [&cfg]() {
        return cfg.z_out_bitwidth == QuantBitWidth::INT8 &&
               cfg.r_out_bitwidth == QuantBitWidth::INT8 &&
               cfg.g_out_bitwidth == QuantBitWidth::INT16 &&
               cfg.h_bitwidth == QuantBitWidth::INT8;
    };

    // INT8 + UINT8 sigmoidï¼šsigmoid è¾“å‡ºï¼ˆz/rï¼‰ç”¨ UINT8ï¼Œå…¶ä»–ç”¨ INT8
    // sigmoid è¾“å‡ºèŒƒå›´ [0,1]ï¼Œä½¿ç”¨ UINT8 [0,255] æ›´åˆé€‚
    auto isInt8WithUint8Sigmoid = [&cfg]() {
        return cfg.z_out_bitwidth == QuantBitWidth::UINT8 &&
               cfg.r_out_bitwidth == QuantBitWidth::UINT8 &&
               cfg.g_out_bitwidth == QuantBitWidth::INT8 &&
               cfg.h_bitwidth == QuantBitWidth::INT8;
    };

    const bool useZoneout = zoneout_prob && zoneout_mask;

    if (isAllInt8()) {
        // å…¨ INT8 é…ç½®ï¼ˆæœ€å¸¸ç”¨ï¼‰
        if (training) {
            if (useZoneout) {
                LAUNCH_KERNEL(int8_t, int8_t, int8_t, int8_t, true, true);
            } else {
                LAUNCH_KERNEL(int8_t, int8_t, int8_t, int8_t, true, false);
            }
        } else {
            if (useZoneout) {
                LAUNCH_KERNEL(int8_t, int8_t, int8_t, int8_t, false, true);
            } else {
                LAUNCH_KERNEL(int8_t, int8_t, int8_t, int8_t, false, false);
            }
        }
    } else if (isAllInt16()) {
        // å…¨ INT16 é…ç½®
        if (training) {
            if (useZoneout) {
                LAUNCH_KERNEL(int16_t, int16_t, int16_t, int16_t, true, true);
            } else {
                LAUNCH_KERNEL(int16_t, int16_t, int16_t, int16_t, true, false);
            }
        } else {
            if (useZoneout) {
                LAUNCH_KERNEL(int16_t, int16_t, int16_t, int16_t, false, true);
            } else {
                LAUNCH_KERNEL(int16_t, int16_t, int16_t, int16_t, false, false);
            }
        }
    } else if (isMixedPrecision()) {
        // æ··åˆç²¾åº¦ï¼šz/r ç”¨ INT8ï¼Œg ç”¨ INT16
        if (training) {
            if (useZoneout) {
                LAUNCH_KERNEL(int8_t, int8_t, int16_t, int8_t, true, true);
            } else {
                LAUNCH_KERNEL(int8_t, int8_t, int16_t, int8_t, true, false);
            }
        } else {
            if (useZoneout) {
                LAUNCH_KERNEL(int8_t, int8_t, int16_t, int8_t, false, true);
            } else {
                LAUNCH_KERNEL(int8_t, int8_t, int16_t, int8_t, false, false);
            }
        }
    } else if (isInt8WithUint8Sigmoid()) {
        // INT8 + UINT8 sigmoidï¼šsigmoid è¾“å‡ºï¼ˆz/rï¼‰ç”¨ UINT8ï¼Œtanh å’Œ h ç”¨ INT8
        if (training) {
            if (useZoneout) {
                LAUNCH_KERNEL(uint8_t, uint8_t, int8_t, int8_t, true, true);
            } else {
                LAUNCH_KERNEL(uint8_t, uint8_t, int8_t, int8_t, true, false);
            }
        } else {
            if (useZoneout) {
                LAUNCH_KERNEL(uint8_t, uint8_t, int8_t, int8_t, false, true);
            } else {
                LAUNCH_KERNEL(uint8_t, uint8_t, int8_t, int8_t, false, false);
            }
        }
    } else {
        // å›é€€åˆ°é»˜è®¤é…ç½®ï¼ˆæ ¹æ® QuantT æ¨¡æ¿å‚æ•°ï¼‰
        if (training) {
            if (useZoneout) {
                LAUNCH_KERNEL(QuantT, QuantT, QuantT, QuantT, true, true);
            } else {
                LAUNCH_KERNEL(QuantT, QuantT, QuantT, QuantT, true, false);
            }
        } else {
            if (useZoneout) {
                LAUNCH_KERNEL(QuantT, QuantT, QuantT, QuantT, false, true);
            } else {
                LAUNCH_KERNEL(QuantT, QuantT, QuantT, QuantT, false, false);
            }
        }
    }

    #undef LAUNCH_KERNEL
}

template<typename T>
void ForwardPassQuant<T>::setRescaleParam(const GRUQuantitativeParameters &parms) {
    const int channel = parms.hidden_ * 3;

    std::vector<int32_t> n_W_mul_x_div_Wx(channel);
    std::vector<int32_t> n_R_mul_h_div_Rh(channel);

    // zé—¨
    std::vector<int32_t> n_bx_to_z(channel);
    std::vector<int32_t> n_br_to_z(channel);

    // ré—¨
    std::vector<int32_t> n_bx_to_r(channel);
    std::vector<int32_t> n_br_to_r(channel);

    // né—¨
    std::vector<int32_t> n_br_to_Rh_add_br(channel);
    std::vector<int32_t> n_bx_to_g(channel);

    for (int idx = 0; idx < channel; ++idx) {// per-channel
        n_W_mul_x_div_Wx[idx] = (parms.exp2_inv_W_[idx] + parms.exp2_inv_x_) - parms.exp2_inv_Wx_;
        n_R_mul_h_div_Rh[idx] = (parms.exp2_inv_R_[idx] + parms.exp2_inv_h_) - parms.exp2_inv_Rh_;

        // zé—¨
        n_bx_to_z[idx] = parms.exp2_inv_bx_[idx] - parms.exp2_inv_z_pre_;
        n_br_to_z[idx] = parms.exp2_inv_br_[idx] - parms.exp2_inv_z_pre_;

        // ré—¨
        n_bx_to_r[idx] = parms.exp2_inv_bx_[idx] - parms.exp2_inv_r_pre_;
        n_br_to_r[idx] = parms.exp2_inv_br_[idx] - parms.exp2_inv_r_pre_;

        // né—¨
        n_br_to_Rh_add_br[idx] = parms.exp2_inv_br_[idx] - parms.exp2_inv_Rh_add_br_;
        n_bx_to_g[idx] = parms.exp2_inv_bx_[idx] - parms.exp2_inv_g_pre_;
    }

    /* init */

    rescale_param_.zp_x_ = parms.zp_x_;
    rescale_param_.zp_h_ = parms.zp_h_;
    h2d(rescale_param_.n_W_mul_x_div_Wx_, n_W_mul_x_div_Wx);
    rescale_param_.zp_Wx_ = parms.zp_Wx_;
    h2d(rescale_param_.n_R_mul_h_div_Rh_, n_R_mul_h_div_Rh);
    rescale_param_.zp_Rh_ = parms.zp_Rh_;

    // zé—¨
    rescale_param_.zp_z_pre_ = parms.zp_z_pre_;
    rescale_param_.zp_z_out_ = parms.zp_z_out_;
    rescale_param_.exp2_inv_Wx_div_z_pre_ = parms.exp2_inv_Wx_ - parms.exp2_inv_z_pre_;
    rescale_param_.exp2_inv_Rh_div_z_pre_ = parms.exp2_inv_Rh_ - parms.exp2_inv_z_pre_;
    h2d(rescale_param_.n_bx_div_z_, n_bx_to_z);
    h2d(rescale_param_.n_br_div_z_, n_br_to_z);

    // ré—¨
    rescale_param_.zp_r_pre_ = parms.zp_r_pre_;
    rescale_param_.zp_r_out_ = parms.zp_r_out_;
    rescale_param_.exp2_inv_Wx_div_r_pre_ = parms.exp2_inv_Wx_ - parms.exp2_inv_r_pre_;
    rescale_param_.exp2_inv_Rh_div_r_pre_ = parms.exp2_inv_Rh_ - parms.exp2_inv_r_pre_;
    h2d(rescale_param_.n_bx_div_r_, n_bx_to_r);
    h2d(rescale_param_.n_br_div_r_, n_br_to_r);

    // né—¨
    rescale_param_.zp_g_pre_ = parms.zp_g_pre_;
    rescale_param_.zp_g_out_ = parms.zp_g_out_;
    rescale_param_.n_Rh_div_Rh_add_br_ =
        parms.exp2_inv_Rh_ - parms.exp2_inv_Rh_add_br_;
    h2d(rescale_param_.n_br_div_Rh_add_br_, n_br_to_Rh_add_br);
    rescale_param_.zp_Rh_add_br_ = parms.zp_Rh_add_br_;
    rescale_param_.n_r_mul_Rh_add_br_div_rRh_ =
        (parms.exp2_inv_r_out_ + parms.exp2_inv_Rh_add_br_) - parms.exp2_inv_rRh_;
    rescale_param_.zp_rRh_ = parms.zp_rRh_;
    rescale_param_.n_Wx_div_g_pre_ = parms.exp2_inv_Wx_ - parms.exp2_inv_g_pre_;
    rescale_param_.n_rRh_div_g_pre_ = parms.exp2_inv_rRh_ - parms.exp2_inv_g_pre_;
    h2d(rescale_param_.exp2_inv_bx_div_g_pre_, n_bx_to_g);

    // h_new
    rescale_param_.one_div_one_minus_update_ = rshift_round(1, -parms.exp2_inv_one_minus_update_);
    rescale_param_.n_z_out_div_one_minus_update_ =
        parms.exp2_inv_z_out_ - parms.exp2_inv_one_minus_update_;
    rescale_param_.zp_one_minus_update_ = parms.zp_one_minus_update_;
    rescale_param_.zp_new_contrib_ = parms.zp_new_contrib_;
    rescale_param_.n_one_minus_update_mul_g_div_new_contrib_ =
        (parms.exp2_inv_one_minus_update_ + parms.exp2_inv_g_out_) - parms.exp2_inv_new_contrib_;
    rescale_param_.zp_old_contrib_ = parms.zp_old_contrib_;
    rescale_param_.n_z_mul_h_div_old_contrib_ =
        (parms.exp2_inv_z_out_ + parms.exp2_inv_h_) - parms.exp2_inv_old_contrib_;
    rescale_param_.n_new_contrib_div_h_ = parms.exp2_inv_new_contrib_ - parms.exp2_inv_h_;
    rescale_param_.n_old_contrib_div_h_ = parms.exp2_inv_old_contrib_ - parms.exp2_inv_h_;

    // TODO delete test
    rescale_param_.test = parms;
    h2d(rescale_param_.test.exp2_inv_bx_dev_, parms.exp2_inv_bx_);
    h2d(rescale_param_.test.exp2_inv_br_dev_, parms.exp2_inv_br_);

    // ä¿å­˜ä½å®½é…ç½®
    bitwidth_config_ = parms.bitwidth_config_;
}

// C = input_size(è¾“å…¥ç»´åº¦), H = hidden_size(éšè—å±‚ç»´åº¦),
// T = time_steps(æ—¶é—´æ­¥), N = batch_size(æ‰¹é‡å¤§å°)
template<typename QuantT>
void ForwardPassQuant<QuantT>::Run(const int steps,          // æ—¶é—´æ­¥æ•°, åºåˆ—é•¿åº¦T
                                   const QuantT *W,          // [C,H*3], è¾“å…¥åˆ°éšè—çŠ¶æ€çš„æƒé‡çŸ©é˜µï¼ˆWxï¼‰, å¯¹åº” GRU çš„ä¸‰ä¸ªé—¨ï¼ˆzã€rã€hï¼‰ã€‚C æ˜¯è¾“å…¥ç‰¹å¾ç»´åº¦ï¼ŒH æ˜¯éšè—çŠ¶æ€ç»´åº¦, ï¼ˆè¡Œä¸»åºï¼Œè®¡ç®— x @ Wï¼‰
                                   const QuantT *R,          // [H,H*3], éšçŠ¶æ€åˆ°éšè—çŠ¶æ€çš„æƒé‡çŸ©é˜µï¼ˆRhï¼‰ï¼Œå¯¹åº” GRU çš„ä¸‰ä¸ªé—¨ï¼ˆzã€rã€hï¼‰. ï¼ˆè¡Œä¸»åºï¼Œè®¡ç®— h @ Rï¼‰
                                   const int32_t *bx,        // [H*3], è¾“å…¥åç½®ï¼ˆbias for Wï¼‰ï¼Œå¯¹åº” zã€rã€h é—¨
                                   const int32_t *br,        // [H*3], éšçŠ¶æ€åç½®ï¼ˆbias for Rï¼‰ï¼Œå¯¹åº” zã€rã€h é—¨
                                   const QuantT *x,          // [N,C], è¾“å…¥åºåˆ—ï¼Œbatch_size = Nï¼Œç‰¹å¾ç»´åº¦ = C
                                   QuantT *h,                // [N,H], è¾“å‡ºéšè—çŠ¶æ€ï¼Œæ¯ä¸ªæ—¶é—´æ­¥ä¿å­˜çš„ GRU éšçŠ¶æ€
                                   QuantT *v,                // [N,H*4], ä¸´æ—¶å­˜å‚¨å‘é‡/ä¸­é—´è®¡ç®—å€¼ï¼Œé€šå¸¸ä¿å­˜ z, r, h_tilde, h_new çš„ä¸­é—´å€¼ï¼Œç”¨äºåå‘ä¼ æ’­æˆ– zoneout
                                   int32_t *tmp_Wx,          // [N,H*3], W * x çš„ä¸´æ—¶ç»“æœ
                                   int32_t *tmp_Rh,          // [N,H*3], R * h çš„ä¸´æ—¶ç»“æœ
                                   const float zoneout_prob, // Zoneout æ¦‚ç‡ï¼Œç”¨äºéšæœºä¸¢å¼ƒéƒ¨åˆ†éšè—çŠ¶æ€
                                   const QuantT *zoneout_mask// Zoneout maskï¼Œ0/1 çŸ©é˜µï¼Œæ§åˆ¶å“ªäº›éšè—å•å…ƒè¢«ä¿ç•™,  // Zoneout mask [N,H]
) {
    static const int32_t alpha = static_cast<int32_t>(1);
    static const int32_t beta = static_cast<int32_t>(0);

    const blas<void>::enable_tensor_cores scoped0(data_->blas_handle);
    const blas<void>::set_pointer_mode scoped1(data_->blas_handle);

    const int batch_size = data_->batch_size;
    const int input_size = data_->input_size;
    const int hidden_size = data_->hidden_size;
    const cublasHandle_t blas_handle = data_->blas_handle;
    const cudaStream_t stream1 = data_->stream[0];
    const cudaStream_t stream2 = data_->stream[1];
    const cudaEvent_t event = data_->event;

    cudaStream_t save_stream;
    cublasGetStream(blas_handle, &save_stream);

    cublasSetStream(blas_handle, stream2);
    blas<QuantT>::gemm(blas_handle,// æå‰ä½¿ç”¨cuBlasè®¡ç®—W * x
                       CUBLAS_OP_N, CUBLAS_OP_N, hidden_size * 3, steps * batch_size,
                       input_size, &alpha, W, hidden_size * 3, x, input_size, &beta,
                       tmp_Wx, hidden_size * 3);

    // è®¡ç®—W_sum_mul_zpç”¨äºè¡¥å¿x_zp
    dev::vector<int32_t> W_sum_mul_x_zp(hidden_size * 3);
    computeWeightSumMulzp(W,
                          W_sum_mul_x_zp.data(),
                          rescale_param_.zp_x_,
                          rescale_param_.n_W_mul_x_div_Wx_.data(),
                          W_sum_mul_x_zp.size(),
                          input_size,
                          stream2);

    // Rhçš„gemméœ€è¦è¡¥å¿h_zp, æ‰€ä»¥æå‰è®¡ç®— h_zp * R_sum * h_zp, stream1
    dev::vector<int32_t> R_sum_mul_h_zp(hidden_size * 3);
    computeWeightSumMulzp(R,
                          R_sum_mul_h_zp.data(),
                          rescale_param_.zp_h_,
                          rescale_param_.n_R_mul_h_div_Rh_.data(),
                          R_sum_mul_h_zp.size(),
                          hidden_size,
                          stream1);

    // åŒæ­¥Wxè®¡ç®—
    cudaEventRecord(event, stream2);

    // åŒæ­¥R_sum_mul_h_zpè®¡ç®—
    cudaEventRecord(event, stream1);

    const int NH = batch_size * hidden_size;

    for (int i = 0; i < steps; ++i) {
        IterateInternal(R, bx, br, h + i * NH, h + (i + 1) * NH, v + i * NH * 4,
                        tmp_Wx + i * NH * 3, tmp_Rh, W_sum_mul_x_zp.data(), R_sum_mul_h_zp.data(), zoneout_prob,
                        zoneout_mask ? zoneout_mask + i * NH : nullptr);
        //        if (i >= 2) { break; }
    }

    cublasSetStream(blas_handle, save_stream);
}

template struct ForwardPassQuant<int8_t>;
template struct ForwardPassQuant<int16_t>;

}// namespace gru
